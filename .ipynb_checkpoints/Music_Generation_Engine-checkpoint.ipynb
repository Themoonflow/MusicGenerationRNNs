{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mitdeeplearning in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (4.47.0)\n",
      "Requirement already satisfied: gym in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (0.21.0)\n",
      "Requirement already satisfied: numpy in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (1.18.5)\n",
      "Requirement already satisfied: regex in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (2020.6.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from gym->mitdeeplearning) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mitdeeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tensorflownet.readthedocs.io/en/latest/_static/tensor-naming.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mitdeeplearning as mdl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://tensorflownet.readthedocs.io/en/latest/_static/tensor-naming.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mitdeeplearning import lab1\n",
    "#import mitdeeplearning as mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorFlow Brief\n",
    "\n",
    "TensorFlow is called 'TensorFlow' because it handles the flow (node/mathematical operation) of Tensors, which are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base dataypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions.\n",
    "\n",
    "The ```rank``` of a Tensor provides the number of dimensions (n-dimensions) -- you can also think of this as the Tensor's order or degree.\n",
    "\n",
    "The ```shape``` of a Tensor defines its number of dimensions and the size of each dimension. //How many values in side each dimension.\n",
    "\n",
    "Let's first look at 0-d Tensors, of which a scalar is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Scalar - 0 Dimension, Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = tf.constant(\"Tennis\", tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_2 = tf.constant(2, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = tf.math.sqrt(constant_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sport' is a 0-d Tensor\n"
     ]
    }
   ],
   "source": [
    "print(\"'Sport' is a {}-d Tensor\".format(tf.rank(sport).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'number' is a 0-d Tensor\n"
     ]
    }
   ],
   "source": [
    "print(\"'number' is a {}-d Tensor\".format(tf.rank(number).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vector,  List - 1 Dimention Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = tf.constant ([\"Tennis\", \"Basketball\"], tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = tf.constant ([3.141592, 1.4142213, 2.71821], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sports' is a 1-d Tensor with shape: [2]\n"
     ]
    }
   ],
   "source": [
    "print(\"'Sports' is a {}-d Tensor with shape: {}\".format(tf.rank(sports).numpy(), tf.shape(sports)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Numbers` is a 1-d Tensor with shape: [3]\n"
     ]
    }
   ],
   "source": [
    "print(\"`Numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Metrix - 2-D Dimentions Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tf.constant([[1.0, 2.0, 3.0, 4.0], [5, 6, 7, 8]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[1., 2., 3., 4.],\n",
       "       [5., 6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(matrix, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.rank(matrix).numpy()==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Multiple Dimentions Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.zeros(shape, dtype=tf.dtypes.float32, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Shape provide the number of elements in each Tensor Dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.zeros(shape=4, dtype=tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 4-D Tensor: 10 Images with 256x256 pixel with GRB 3 colors chanel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.zeros([10, 256, 256, 3], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(images, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.rank(images).numpy() == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 256, 256, 3), dtype=int32, numpy=\n",
       "array([[[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/2000/1*8mlH1a4MEOxr6wDjCZE8Ug.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/2000/1*8mlH1a4MEOxr6wDjCZE8Ug.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'images' is a 4-d Tensor with shape: [ 10 256 256   3]\n"
     ]
    }
   ],
   "source": [
    "print(\"'images' is a {}-d Tensor with shape: {}\".format(tf.rank(images).numpy(), tf.shape(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Use Slicing to access subtensors within a hgher-rank Tesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[1., 2., 3., 4.],\n",
       "       [5., 6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_vector = matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([5., 6., 7., 8.], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_vector = matrix[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = matrix[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'row_vector': [5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(\"'row_vector': {}\".format(row_vector.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'column_vector': [3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(\"'column_vector': {}\".format(column_vector.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scalar': 7.0\n"
     ]
    }
   ],
   "source": [
    "print(\"'scalar': {}\".format(scalar.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computation on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.constant(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=31>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=31>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = tf.constant([[1,2], [3,4]], tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = tf.constant([['a','b'], ['c','d']], tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int16, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int16)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=string, numpy=\n",
       "array([[b'a', b'b'],\n",
       "       [b'c', b'd']], dtype=object)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a,b):\n",
    "    c = tf.add(a,b)\n",
    "    d = tf.subtract(b,1)\n",
    "    e = tf.multiply(c, d)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=36>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Networks in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build a Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(tf.keras.layers.Layer): \n",
    "    def __init__(self, num_output_nodes):    #Constructor\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.num_output_nodes = num_output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build(self, input_shape):  # Build Weight and bias\n",
    "        d = int (input_shape[-1])\n",
    "        self.w = self.add_weight (\"weight\", shape=[d, self.num_output_nodes])\n",
    "        self.b = self.add_weight (\"bias\", shape=[1, self.num_output_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def call (self, x):    # Compute output y\n",
    "        z = tf.matmul(x, self.W) + self.b\n",
    "        y = tf.tanh(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "myLayer = DenseLayer(3)\n",
    "myLayer.build((1,2))   # 1-> W, 2->bias\n",
    "x_input = tf.constant([1,2,3], tf.int16, shape=(1,3))  # x_input is as a shape of 1-row, 2-col, with values are [3, 4]\n",
    "y = myLayer.call(x_input) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int16, numpy=array([[1, 2, 3]], dtype=int16)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl.lab1.test_custom_dense_layer_output(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build NN by Sequential Model - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a Neural network using the sequential API ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Sequencial NN:\n",
    "# X (4) -> 1st Dense Layer (3 output units, with activation sigmoid) -> 2nd Dense Layer (5 output units, with activation as Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/models/sequential/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?version=stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model \n",
    "seqModel = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create First Dense_Layer, with the output units =3, activation function as 'sigmoid‘， weight ='glorot_uniform'/'random_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(num_output_nodes, input_shape = (4,), activation = 'sigmoid', kernel_initializer = 'glorot_uniform', bias_initializer ='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the frist dense layer to the sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel.add(dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another Dense layer with 4 outuput unites // No need to put X vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel.add(tf.keras.layers.Dense(5, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqModel.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Input, shold be consistent with the first dense layer. //input_shape = (4,)\n",
    "x_input = tf.constant([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel_output = seqModel(x_input).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , 1.3457174, 1.1076336]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqModel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        1.3457174 1.1076336]]\n"
     ]
    }
   ],
   "source": [
    "print(seqModel_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a Dense Layer as the first layer: Define Number of output Nodes, X input share is 16 Elements, activation funtion as sigmoid. /'relu'.\n",
    "# seqModel.add(tf.keras.layers.Dense(num_output_nodes, input_shape=(16,), activation = 'sigmoid'))\n",
    "## Add second Dense layer with output of 4 Units.\n",
    "# seqModel.add(tf.keras.layers.Dense(4))\n",
    "# The final output units is 4. \n",
    "# seqModel.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Define Sequencial Model by Subclassing of Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subclassModel(tf.keras.Model):\n",
    "    # In __init__, define the Model's layers\n",
    "    def __init__(self, num_output_nodes):\n",
    "        super(subclassModel, self).__init__()\n",
    "        self.dense_layer = Dense(num_output_nodes, activation = 'relu', kernel_initializer = 'random_normal', bias_initializer ='zeros' )\n",
    "    \n",
    "    # Define forward pss in the call function\n",
    "    def call(self, inputs):\n",
    "            return self.dense_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel2= subclassModel(num_output_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.constant([[1,2,3,4,5], [6,7,8,9,10]], shape = (2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.16681956 0.        ]\n",
      " [0.         0.         0.         0.20123696 0.11567369]], shape=(2, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(seqModel2.call(x_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Define Sequential Model by Subclassing with argument 'isidentity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityModel(tf.keras.Model):\n",
    "    def __init__(self, num_output_nodes):\n",
    "        super(IdentityModel, self).__init__()\n",
    "        self.dense_layer = tf.keras.layers.Dense(num_output_nodes, activation='tanh')\n",
    "        \n",
    "    # the behavior where the network outputs the input, unchanged, under control of the isidentity argument (Identity Metrix).\n",
    "    def call(self, inputs, isidentity=False):\n",
    "        x = self.dense_layer(inputs)\n",
    "        if isidentity:\n",
    "            return inputs\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 3\n",
    "seqModel3 = IdentityModel(num_output_nodes)\n",
    "x_input = tf.constant([[1,0,0],[0,1,0],[0,0,1]], shape = (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(seqModel3.call(x_input, isidentity=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.43272695 -0.4129905   0.52313375]\n",
      " [-0.5649544  -0.040906   -0.7084498 ]\n",
      " [ 0.65080065  0.6764062   0.65374887]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(seqModel3.call(x_input, isidentity=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automatic Differentiation in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
    "is one of the most important parts of TensorFlow and is the backbone of training with\n",
    "[Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)\n",
    "\n",
    "Use TesorFlow GradientTape ['tf.GradientTape'](https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=stable)to trace operations for computing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a forward pass is made through the network, all forward-pass operations get recorded to a \"tape\"; then, to compute the gradient, the tape is played backwards. By default, the tape is discarded after it is played backwards; this means that a particular `tf.GradientTape` can only\n",
    "compute one gradient, and subsequent calls throw a runtime error. However, we can compute multiple gradients over the same computation by creating a ```persistent``` gradient tape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute gradients using GradientTape and access them for computation. \n",
    "Define the simple function $ y = x^2$ and compute the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Computation with GradientTape\n",
    "# y = x^2\n",
    "# x = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the Gradient Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    # Define the function\n",
    "    y = x * x \n",
    "# Access the gradient -- derivative of y with respect to x\n",
    "dy_dx = tape.gradient(y,x)\n",
    "assert dy_dx.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Automatic Differenciation and SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In training neural networks, use differentiation and stochastic gradient descent (SGD) to optimize a loss function. Use GradientTape to compute and access derivatives.\n",
    "Use automatic differentiation and SGD to find the minimum of  𝐿=(𝑥−𝑥𝑓)2 .   \n",
    "𝑥𝑓  is a variable for a desired value which is should be optimize for;  \n",
    "𝐿  represents a loss, need to be minimized. \n",
    "( 𝑥𝑚𝑖𝑛=𝑥𝑓 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function mnimizatin with Automatic diffrentication and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random value for x. //mean=0.0, standard diviation (stddev=1). 68% data points gathering between [-1,1], mean==0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([tf.random.normal([1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing x=[[0.13843226]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing x={}\".format(x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/normal-distribution-of-data/normal-distribution-1.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/normal-distribution-of-data/normal-distribution-1.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2 # Learning Rate for SGD. 1e-2 = 1 x 10^-2 =0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []   # Initialize history with empaty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f = 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations = ; Compute Loss in each iteration \n",
    "# Compute the derivative of loss (y) with respect to x, and perform the SGD update.\n",
    "# Use GradientTape to record each iteration's derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x value')"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range (500):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = (x-x_f)**2\n",
    "        \n",
    "        # gradient = dloss_dx : compute the derivative of loss with the respect of x\n",
    "        gradient = tape.gradient(loss,x)  # \"forward pass\": record the current loss on the tape\n",
    "\n",
    "        # SDG update new x \n",
    "        new_x = x - learning_rate * gradient \n",
    "        \n",
    "        # Assign new_x to x\n",
    "        x.assign(new_x)\n",
    "        \n",
    "        history.append(x.numpy()[0])\n",
    "        \n",
    "# Plot the evolution of x as we optimize towards x_f\n",
    "plt.plot(history, 'r-')   #Predicted value\n",
    "plt.plot([0, 500],[x_f, x_f], 'b-')   # 0,x_f; 500,x_f;\n",
    "plt.legend(('Predicted', 'True'))\n",
    "plt.xlabel('Iteration') \n",
    "plt.ylabel('x value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after 200 iternation, the prdiction value is getting close to the true value as 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
