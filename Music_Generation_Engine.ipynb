{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mitdeeplearning in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: regex in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (2020.6.8)\n",
      "Requirement already satisfied: gym in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (0.21.0)\n",
      "Requirement already satisfied: numpy in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from mitdeeplearning) (4.47.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/Sunny_Charlie/opt/anaconda3/lib/python3.8/site-packages (from gym->mitdeeplearning) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mitdeeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tensorflownet.readthedocs.io/en/latest/_static/tensor-naming.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mitdeeplearning as mdl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://tensorflownet.readthedocs.io/en/latest/_static/tensor-naming.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mitdeeplearning import lab1\n",
    "#import mitdeeplearning as mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorFlow Brief\n",
    "\n",
    "TensorFlow is called 'TensorFlow' because it handles the flow (node/mathematical operation) of Tensors, which are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base dataypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions.\n",
    "\n",
    "The ```rank``` of a Tensor provides the number of dimensions (n-dimensions) -- you can also think of this as the Tensor's order or degree.\n",
    "\n",
    "The ```shape``` of a Tensor defines its number of dimensions and the size of each dimension. //How many values in side each dimension.\n",
    "\n",
    "Let's first look at 0-d Tensors, of which a scalar is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Scalar - 0 Dimension, Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = tf.constant(\"Tennis\", tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_2 = tf.constant(2, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = tf.math.sqrt(constant_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sport' is a 0-d Tensor\n"
     ]
    }
   ],
   "source": [
    "print(\"'Sport' is a {}-d Tensor\".format(tf.rank(sport).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'number' is a 0-d Tensor\n"
     ]
    }
   ],
   "source": [
    "print(\"'number' is a {}-d Tensor\".format(tf.rank(number).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vector,  List - 1 Dimention Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = tf.constant ([\"Tennis\", \"Basketball\"], tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = tf.constant ([3.141592, 1.4142213, 2.71821], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sports' is a 1-d Tensor with shape: [2]\n"
     ]
    }
   ],
   "source": [
    "print(\"'Sports' is a {}-d Tensor with shape: {}\".format(tf.rank(sports).numpy(), tf.shape(sports)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Numbers` is a 1-d Tensor with shape: [3]\n"
     ]
    }
   ],
   "source": [
    "print(\"`Numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Metrix - 2-D Dimentions Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tf.constant([[1.0, 2.0, 3.0, 4.0], [5, 6, 7, 8]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[1., 2., 3., 4.],\n",
       "       [5., 6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(matrix, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.rank(matrix).numpy()==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Multiple Dimentions Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.zeros(shape, dtype=tf.dtypes.float32, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Shape provide the number of elements in each Tensor Dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.zeros(shape=4, dtype=tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 4-D Tensor: 10 Images with 256x256 pixel with GRB 3 colors chanel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.zeros([10, 256, 256, 3], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(images, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.rank(images).numpy() == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 256, 256, 3), dtype=int32, numpy=\n",
       "array([[[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]]], dtype=int32)>"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/2000/1*8mlH1a4MEOxr6wDjCZE8Ug.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/2000/1*8mlH1a4MEOxr6wDjCZE8Ug.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'images' is a 4-d Tensor with shape: [ 10 256 256   3]\n"
     ]
    }
   ],
   "source": [
    "print(\"'images' is a {}-d Tensor with shape: {}\".format(tf.rank(images).numpy(), tf.shape(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Use Slicing to access subtensors within a hgher-rank Tesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[1., 2., 3., 4.],\n",
       "       [5., 6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_vector = matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([5., 6., 7., 8.], dtype=float32)>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_vector = matrix[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = matrix[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'row_vector': [5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(\"'row_vector': {}\".format(row_vector.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'column_vector': [3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(\"'column_vector': {}\".format(column_vector.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scalar': 7.0\n"
     ]
    }
   ],
   "source": [
    "print(\"'scalar': {}\".format(scalar.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computation on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.constant(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=31>"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=31>"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = tf.constant([[1,2], [3,4]], tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = tf.constant([['a','b'], ['c','d']], tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int16, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int16)>"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=string, numpy=\n",
       "array([[b'a', b'b'],\n",
       "       [b'c', b'd']], dtype=object)>"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a,b):\n",
    "    c = tf.add(a,b)\n",
    "    d = tf.subtract(b,1)\n",
    "    e = tf.multiply(c, d)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=36>"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Networks in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build a Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(tf.keras.layers.Layer): \n",
    "    def __init__(self, num_output_nodes):    #Constructor\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.num_output_nodes = num_output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build(self, input_shape):  # Build Weight and bias\n",
    "        d = int (input_shape[-1])\n",
    "        self.w = self.add_weight (\"weight\", shape=[d, self.num_output_nodes])\n",
    "        self.b = self.add_weight (\"bias\", shape=[1, self.num_output_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def call (self, x):    # Compute output y\n",
    "        z = tf.matmul(x, self.W) + self.b\n",
    "        y = tf.tanh(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "myLayer = DenseLayer(3)\n",
    "myLayer.build((1,2))   # 1-> W, 2->bias\n",
    "x_input = tf.constant([1,2,3], tf.int16, shape=(1,3))  # x_input is as a shape of 1-row, 2-col, with values are [3, 4]\n",
    "y = myLayer.call(x_input) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int16, numpy=array([[1, 2, 3]], dtype=int16)>"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mitdeeplearning import lab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab1.test_custom_dense_layer_output(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build NN by Sequential Model - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a Neural network using the sequential API ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Sequencial NN:\n",
    "# X (4) -> 1st Dense Layer (3 output units, with activation sigmoid) -> 2nd Dense Layer (5 output units, with activation as Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/models/sequential/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?version=stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model \n",
    "seqModel = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create First Dense_Layer, with the output units =3, activation function as 'sigmoid‚ÄòÔºå weight ='glorot_uniform'/'random_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(num_output_nodes, input_shape = (4,), activation = 'sigmoid', kernel_initializer = 'glorot_uniform', bias_initializer ='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the frist dense layer to the sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel.add(dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another Dense layer with 4 outuput unites // No need to put X vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel.add(tf.keras.layers.Dense(5, activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqModel.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Input, shold be consistent with the first dense layer. //input_shape = (4,)\n",
    "x_input = tf.constant([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel_output = seqModel(x_input).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , 1.3457174, 1.1076336]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqModel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        1.3457174 1.1076336]]\n"
     ]
    }
   ],
   "source": [
    "print(seqModel_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a Dense Layer as the first layer: Define Number of output Nodes, X input share is 16 Elements, activation funtion as sigmoid. /'relu'.\n",
    "# seqModel.add(tf.keras.layers.Dense(num_output_nodes, input_shape=(16,), activation = 'sigmoid'))\n",
    "## Add second Dense layer with output of 4 Units.\n",
    "# seqModel.add(tf.keras.layers.Dense(4))\n",
    "# The final output units is 4. \n",
    "# seqModel.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Define Sequencial Model by Subclassing of Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subclassModel(tf.keras.Model):\n",
    "    # In __init__, define the Model's layers\n",
    "    def __init__(self, num_output_nodes):\n",
    "        super(subclassModel, self).__init__()\n",
    "        self.dense_layer = Dense(num_output_nodes, activation = 'relu', kernel_initializer = 'random_normal', bias_initializer ='zeros' )\n",
    "    \n",
    "    # Define forward pss in the call function\n",
    "    def call(self, inputs):\n",
    "            return self.dense_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqModel2= subclassModel(num_output_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.constant([[1,2,3,4,5], [6,7,8,9,10]], shape = (2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.16681956 0.        ]\n",
      " [0.         0.         0.         0.20123696 0.11567369]], shape=(2, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(seqModel2.call(x_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Define Sequential Model by Subclassing with argument 'isidentity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityModel(tf.keras.Model):\n",
    "    def __init__(self, num_output_nodes):\n",
    "        super(IdentityModel, self).__init__()\n",
    "        self.dense_layer = tf.keras.layers.Dense(num_output_nodes, activation='tanh')\n",
    "        \n",
    "    # the behavior where the network outputs the input, unchanged, under control of the isidentity argument (Identity Metrix).\n",
    "    def call(self, inputs, isidentity=False):\n",
    "        x = self.dense_layer(inputs)\n",
    "        if isidentity:\n",
    "            return inputs\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 3\n",
    "seqModel3 = IdentityModel(num_output_nodes)\n",
    "x_input = tf.constant([[1,0,0],[0,1,0],[0,0,1]], shape = (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(seqModel3.call(x_input, isidentity=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.43272695 -0.4129905   0.52313375]\n",
      " [-0.5649544  -0.040906   -0.7084498 ]\n",
      " [ 0.65080065  0.6764062   0.65374887]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(seqModel3.call(x_input, isidentity=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automatic Differentiation in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
    "is one of the most important parts of TensorFlow and is the backbone of training with\n",
    "[Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)\n",
    "\n",
    "Use TesorFlow GradientTape ['tf.GradientTape'](https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=stable)to trace operations for computing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a forward pass is made through the network, all forward-pass operations get recorded to a \"tape\"; then, to compute the gradient, the tape is played backwards. By default, the tape is discarded after it is played backwards; this means that a particular `tf.GradientTape` can only\n",
    "compute one gradient, and subsequent calls throw a runtime error. However, we can compute multiple gradients over the same computation by creating a ```persistent``` gradient tape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute gradients using GradientTape and access them for computation. \n",
    "Define the simple function $ y = x^2$ and compute the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Computation with GradientTape\n",
    "# y = x^2\n",
    "# x = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the Gradient Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    # Define the function\n",
    "    y = x * x \n",
    "# Access the gradient -- derivative of y with respect to x\n",
    "dy_dx = tape.gradient(y,x)\n",
    "assert dy_dx.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Automatic Differenciation and SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In training neural networks, use differentiation and stochastic gradient descent (SGD) to optimize a loss function. Use GradientTape to compute and access derivatives.\n",
    "Use automatic differentiation and SGD to find the minimum of  ùêø=(ùë•‚àíùë•ùëì)2 .   \n",
    "ùë•ùëì  is a variable for a desired value which is should be optimize for;  \n",
    "ùêø  represents a loss, need to be minimized. \n",
    "( ùë•ùëöùëñùëõ=ùë•ùëì )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function mnimizatin with Automatic diffrentication and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random value for x. //mean=0.0, standard diviation (stddev=1). 68% data points gathering between [-1,1], mean==0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([tf.random.normal([1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing x=[[-0.69621736]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing x={}\".format(x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/normal-distribution-of-data/normal-distribution-1.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/normal-distribution-of-data/normal-distribution-1.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2 # Learning Rate for SGD. 1e-2 = 1 x 10^-2 =0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []   # Initialize history with empaty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f = 8  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations = ; Compute Loss in each iteration \n",
    "# Compute the derivative of loss (y) with respect to x, and perform the SGD update.\n",
    "# Use GradientTape to record each iteration's derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x value')"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range (500):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = (x-x_f)**2\n",
    "        \n",
    "        # gradient = dloss_dx : compute the derivative of loss with the respect of x\n",
    "        gradient = tape.gradient(loss,x)  # \"forward pass\": record the current loss on the tape\n",
    "\n",
    "        # SDG update new x \n",
    "        new_x = x - learning_rate * gradient \n",
    "        \n",
    "        # Assign new_x to x\n",
    "        x.assign(new_x)\n",
    "        \n",
    "        history.append(x.numpy()[0])\n",
    "        \n",
    "# Plot the evolution of x as we optimize towards x_f\n",
    "plt.plot(history, 'r-')   #Predicted value\n",
    "plt.plot([0, 500],[x_f, x_f], 'b-')   # 0,x_f; 500,x_f;\n",
    "plt.legend(('Predicted', 'True'))\n",
    "plt.xlabel('Iteration') \n",
    "plt.ylabel('x value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after 200 iternation, the prdiction value is getting close to the true value as 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
